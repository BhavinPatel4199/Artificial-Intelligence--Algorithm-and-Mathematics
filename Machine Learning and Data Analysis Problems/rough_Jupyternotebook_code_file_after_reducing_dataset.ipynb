{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da13ff-d932-450c-95fb-5ce546f715fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71e7dbb0-14d0-40bc-a724-9a1c69e00139",
   "metadata": {},
   "source": [
    "## Evaluation after reducing the dataset from 25000 rows to 10000 rows :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ecf4535b-3b53-49f1-b534-9d52d86a8fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples: 5000\n",
      "Number of negative samples: 5000\n"
     ]
    }
   ],
   "source": [
    "x_reduce = main_df['cleaned_text']\n",
    "y_reduce = main_df['target']\n",
    "\n",
    "x_red, _, y_red, _ = train_test_split(x_reduce, y_reduce, test_size=15000, stratify=y_reduce, random_state=42)\n",
    "\n",
    "reduced_df = pd.DataFrame({'cleaned_text': x_red, 'target': y_red})\n",
    "\n",
    "print(\"Number of positive samples:\", reduced_df['target'].sum())\n",
    "print(\"Number of negative samples:\", len(reduced_df) - reduced_df['target'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cea50d55-9b85-44a7-93c0-dd86d591cb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>[assy, mcgee, show, really, certain, age, appr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15793</th>\n",
       "      <td>[mockney, come, brighton, despite, poor, recep...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10349</th>\n",
       "      <td>[rented, movie, library, hard, find, good, rea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10157</th>\n",
       "      <td>[movie, definitely, case, style, substance, st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>[ben, stryker, exgreen, beret, stop, little, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17439</th>\n",
       "      <td>[favourite, indian, movie, time, comic, genius...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>[reason, bad, movie, badly, written, entirely,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10668</th>\n",
       "      <td>[although, movie, slow, dreamlike, almost, mes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>[unlikely, love, triangle, set, 19th, century,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10184</th>\n",
       "      <td>[similar, story, line, done, many, time, impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            cleaned_text  target\n",
       "1310   [assy, mcgee, show, really, certain, age, appr...       1\n",
       "15793  [mockney, come, brighton, despite, poor, recep...       0\n",
       "10349  [rented, movie, library, hard, find, good, rea...       0\n",
       "10157  [movie, definitely, case, style, substance, st...       1\n",
       "10011  [ben, stryker, exgreen, beret, stop, little, t...       0\n",
       "...                                                  ...     ...\n",
       "17439  [favourite, indian, movie, time, comic, genius...       1\n",
       "6420   [reason, bad, movie, badly, written, entirely,...       0\n",
       "10668  [although, movie, slow, dreamlike, almost, mes...       0\n",
       "4289   [unlikely, love, triangle, set, 19th, century,...       1\n",
       "10184  [similar, story, line, done, many, time, impro...       0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "19deb9ae-904d-46c2-bcc9-068989e40d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    5000\n",
      "1    5000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_groupby = reduced_df.groupby('target').size()\n",
    "print(target_groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b1d7ea97-9c9a-487c-b5ae-526b5bab5696",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1310     [assy, mcgee, show, really, certain, age, appr...\n",
       "15793    [mockney, come, brighton, despite, poor, recep...\n",
       "10349    [rented, movie, library, hard, find, good, rea...\n",
       "10157    [movie, definitely, case, style, substance, st...\n",
       "10011    [ben, stryker, exgreen, beret, stop, little, t...\n",
       "                               ...                        \n",
       "17439    [favourite, indian, movie, time, comic, genius...\n",
       "6420     [reason, bad, movie, badly, written, entirely,...\n",
       "10668    [although, movie, slow, dreamlike, almost, mes...\n",
       "4289     [unlikely, love, triangle, set, 19th, century,...\n",
       "10184    [similar, story, line, done, many, time, impro...\n",
       "Name: cleaned_text, Length: 10000, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1310     1\n",
       "15793    0\n",
       "10349    0\n",
       "10157    1\n",
       "10011    0\n",
       "        ..\n",
       "17439    1\n",
       "6420     0\n",
       "10668    0\n",
       "4289     1\n",
       "10184    0\n",
       "Name: target, Length: 10000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = reduced_df['cleaned_text']\n",
    "b = reduced_df['target']\n",
    "display(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c242768e-5e22-4dfa-8549-9a88aa775ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Test split ratio is : [80, 20] \n",
      "\n",
      "Training set:\n",
      "X_train shape: (8000,)\n",
      "y_train shape: (2000,)\n",
      "\n",
      "Testing set:\n",
      "X_test shape: (8000,)\n",
      "y_test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "a_training, a_testing, b_training, b_testing = train_test_split(a, b, test_size=0.2, stratify=b, random_state=78)\n",
    "\n",
    "print('Train Test split ratio is : [80, 20]','\\n')\n",
    "print(\"Training set:\")\n",
    "print(\"X_train shape:\", a_training.shape)\n",
    "print(\"y_train shape:\", a_testing.shape)\n",
    "\n",
    "\n",
    "print(\"\\nTesting set:\")\n",
    "print(\"X_test shape:\", b_training.shape)\n",
    "print(\"y_test shape:\", b_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f21b7b08-8808-4d04-8b8c-058aac19e935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_training = [' '.join(doc) for doc in a_training]\n",
    "a_testing = [' '.join(doc) for doc in a_testing]\n",
    "\n",
    "a_train_tfidf = tfidf_vectorizer.fit_transform(a_training)\n",
    "\n",
    "a_test_tfidf = tfidf_vectorizer.transform(a_testing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05abf1-4e3b-499c-b998-a22a7852b643",
   "metadata": {},
   "source": [
    "## Perform GridSearchCV for Random Forest and Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8e294aad-e763-4fbe-9a9a-70f873e717ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency for Random Forest:  701.8885161876678\n"
     ]
    }
   ],
   "source": [
    "gscv_rf = GridSearchCV(rf_classifier, param_grid_rf, cv=5, n_jobs=5)\n",
    "\n",
    "rf_st_time = time.time()\n",
    "gscv_rf.fit(a_train_tfidf, b_training)\n",
    "latency_rf = time.time() - rf_st_time\n",
    "\n",
    "print(\"Latency for Random Forest: \", latency_rf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8db35d26-c5cf-42df-89dc-1d12598c7cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.675348154703777"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latency_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c196b313-1902-415e-9409-2a79bd19de8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest took 0.4445891359117296 minutes to perform the Grid search CV\n"
     ]
    }
   ],
   "source": [
    "tak_time_rf = latency_rf/60\n",
    "print(f\"Random Forest took {tak_time_rf} minutes to perform the Grid search CV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db97e09-72a6-4139-8a5b-8c3e1f4b498d",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ce083506-1ea0-4307-8a7a-b8ad6c62c329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters obtained after performing the GSVC : {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 300} \n",
      "\n",
      "Model Best score : 85.08\n"
     ]
    }
   ],
   "source": [
    "bp_rf = gscv_rf.best_params_\n",
    "bs_rf = gscv_rf.best_score_\n",
    "print(\"Best Parameters obtained after performing the GSVC :\", bp_rf, '\\n')\n",
    "print(\"Model Best score :\", round(bs_rf, 4)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0200860e-1748-40d8-a32f-7e7f107e3271",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "raw",
   "id": "21082ee4-f900-404e-89cf-7da9a732c804",
   "metadata": {
    "tags": []
   },
   "source": [
    "grid_search_gb = GridSearchCV(gb_classifier, param_grid_gb, cv=5, n_jobs=-5)\n",
    "start_time2 = time.time()   \n",
    "grid_search_gb.fit(X_train_tfidf, Y_train)\n",
    "print(grid_search_gb.refit_time_, '\\n')\n",
    "latency2 = time.time() - start_time2 "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6744c5cc-dbd6-4d48-9cf8-cded1ea4f36a",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(\"Latency for Gradient Boosting: \", latency2)\n",
    "best_params = grid_search_xgb.best_params_\n",
    "best_score = grid_search_xgb.best_score_\n",
    "\n",
    "print(\"Best performing model parameters:\")\n",
    "print(best_params)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447fce3c-df73-4ca8-ba99-770b9d7633a0",
   "metadata": {},
   "source": [
    "### Going to use the XGB, reason because the Gradient boosting was taking so long to perform GSCV I have almost wait for around 8-10 hours for the result but i did not received the output. So later i decide to move with XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f4fba-338c-40b1-83d0-4c464150f9f6",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f649e-78b9-44d7-8773-957a0037cb66",
   "metadata": {},
   "source": [
    "## Perform GridSearchCV for XGB :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5ada2cf-f65c-4fd6-a40d-def970b0e1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency for Random Forest:  7599.761258840561\n"
     ]
    }
   ],
   "source": [
    "gsvc_xgb = GridSearchCV(xgb_classifier, param_grid_xgb, cv=5, n_jobs=-5)\n",
    "\n",
    "start_time_xgb = time.time()\n",
    "\n",
    "gsvc_xgb.fit(a_train_tfidf, b_training)\n",
    "\n",
    "latency_xgb = time.time() - start_time_xgb\n",
    "\n",
    "print(\"Latency for Random Forest: \", latency_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8748ba3b-c316-4880-9266-b9ea2d95a6bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB took 126.66268764734268 minutes to perform the Grid search CV\n"
     ]
    }
   ],
   "source": [
    "tak_time_xgb = latency_xgb/60\n",
    "print(f\"XGB took {tak_time_xgb} minutes to perform the Grid search CV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd51fcf2-0016-4299-b8eb-d021fec078c6",
   "metadata": {},
   "source": [
    "#### Time required to perform GSCV using XGB classifier is 2 hours and around 6 minutes to complete the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c4f42a5-3a4b-4dad-910f-6227d17b1ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters obtained after performing the GSVC : {'gamma': 0.2, 'learning_rate': 0.2, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 300} \n",
      "\n",
      "Model Best score : 85.89\n"
     ]
    }
   ],
   "source": [
    "bp_xgb = gsvc_xgb.best_params_\n",
    "bs_xgb = gsvc_xgb.best_score_\n",
    "\n",
    "print(\"Best Parameters obtained after performing the GSVC :\", bp_xgb, '\\n')\n",
    "print(\"Model Best score :\", round(bs_xgb, 4)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063436df-b8a6-4eaa-84a0-61ff81c2d844",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f141b80-9600-4e5f-beee-b6b85e78f6a4",
   "metadata": {},
   "source": [
    "# Perform Final evaluation of models on the best parameter settings using the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2ea2df02-78e8-465b-8c3b-4ff0af09b601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGB model: 86.0\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      5000\n",
      "           1       0.86      0.86      0.86      5000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_rf = RandomForestClassifier(**bp_rf)\n",
    "\n",
    "best_model_rf.fit(a_train_tfidf, b_training)\n",
    "\n",
    "b_pred_rf = best_model_rf.predict(a_test_tfidf)\n",
    "\n",
    "accuracy_rf_2 = accuracy_score(b_testing , b_pred_rf)\n",
    "print(\"Accuracy of XGB model:\", round(accuracy_rf_2, 2)*100)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(b_testing, b_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dad1db55-b561-4995-8692-6618f89b2ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGB model: 86.59\n",
      " XGB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86      5000\n",
      "           1       0.85      0.88      0.87      5000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_XGB = xgb.XGBClassifier(**bp_xgb)\n",
    "\n",
    "best_model_XGB.fit(a_train_tfidf, b_training)\n",
    "\n",
    "b_pred_xgb = best_model_XGB.predict(a_test_tfidf)\n",
    "\n",
    "accuracy_xgb = accuracy_score(b_testing, b_pred_xgb)\n",
    "print(\"Accuracy of XGB model:\", round(accuracy_xgb, 4)*100)\n",
    "\n",
    "print(\" XGB Classification Report:\")\n",
    "print(classification_report(b_testing, b_pred_xgb))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
